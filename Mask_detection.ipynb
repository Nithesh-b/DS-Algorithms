{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask detection.ipynb",
      "provenance": [],
      "mount_file_id": "1DS2z_nnPBg48Xux5u-FNS_LIBtwSo_k2",
      "authorship_tag": "ABX9TyMpk0z5kbMjLQ1dztp4ylED",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nithesh-b/config/blob/master/Mask_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drA6_aNTR29e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "import keras\n",
        "\n",
        "import random\n",
        "\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from shutil import copyfile\n",
        "\n",
        "from os import getcwd\n",
        "\n",
        "from os import listdir\n",
        "\n",
        "import cv2\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import imutils\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import matplotlib.image  as mpimg"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG6uJLI7R_jA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f2e45bd2-cfa4-4afe-9831-4f933a356b15"
      },
      "source": [
        "def data_summary(main_path):\n",
        "\n",
        "    withmask_path = main_path+'masked'\n",
        "\n",
        "    withoutmask_path = main_path+'unmasked'\n",
        "\n",
        "    # number of (images) that are in the the folder named 'masked' \n",
        "\n",
        "    m_pos = len(listdir('/content/drive/My Drive/dataset/train_validate/masked'))\n",
        "\n",
        "\n",
        " \n",
        "    # number of (images) that are in the the folder named 'without_mask' \n",
        "\n",
        "    m_neg = len(listdir('/content/drive/My Drive/dataset/train_validate/unmasked'))\n",
        "\n",
        "    # number of all examples\n",
        "\n",
        "    m = (m_pos+m_neg)\n",
        "\n",
        "    pos_prec = (m_pos* 100.0)/ m\n",
        "\n",
        "    neg_prec = (m_neg* 100.0)/ m\n",
        "\n",
        "    print(f\"Number of examples: {m}\")\n",
        "\n",
        "    print(f\"Percentage of positive examples: {pos_prec}%, number of pos examples: {m_pos}\") \n",
        "\n",
        "    print(f\"Percentage of negative examples: {neg_prec}%, number of neg examples: {m_neg}\")    \n",
        "\n",
        "\n",
        "augmented_data_path = '/content/drive/My Drive/dataset/train_validate'    \n",
        "\n",
        "data_summary(augmented_data_path)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of examples: 1727\n",
            "Percentage of positive examples: 51.36074116965837%, number of pos examples: 887\n",
            "Percentage of negative examples: 48.63925883034163%, number of neg examples: 840\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88IiYDl3V4yx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "e02b9585-ac92-430e-bb57-4daf34fd4e66"
      },
      "source": [
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "\n",
        "    dataset = []  \n",
        "\n",
        "    for unitData in os.listdir(SOURCE):\n",
        "\n",
        "        data = SOURCE + unitData\n",
        "\n",
        "        if(os.path.getsize(data) > 0):\n",
        "\n",
        "            dataset.append(unitData)\n",
        "\n",
        "        else:\n",
        "\n",
        "            print('Skipped ' + unitData)\n",
        "\n",
        "            print('Invalid file i.e zero size')  \n",
        "\n",
        "    train_set_length = int(len(dataset) * SPLIT_SIZE)\n",
        "\n",
        "    test_set_length = int(len(dataset) - train_set_length)\n",
        "\n",
        "    shuffled_set = random.sample(dataset, len(dataset))\n",
        "\n",
        "    train_set = dataset[0:train_set_length]\n",
        "\n",
        "    test_set = dataset[-test_set_length:]     \n",
        "\n",
        "    for unitData in train_set:\n",
        "\n",
        "        temp_train_set = SOURCE + unitData\n",
        "\n",
        "        final_train_set = TRAINING + unitData\n",
        "\n",
        "        copyfile(temp_train_set, final_train_set)  \n",
        "\n",
        "    for unitData in test_set:\n",
        "\n",
        "        temp_test_set = SOURCE + unitData\n",
        "\n",
        "        final_test_set = TESTING + unitData\n",
        "\n",
        "        copyfile(temp_test_set, final_test_set)      \n",
        "\n",
        "WITHMASK_SOURCE_DIR = \"experiements/dest_folder/val/with_mask/\"\n",
        "\n",
        "TRAINING_WITHMASK_DIR = \"experiements/dest_folder/train/with_mask/\"\n",
        "\n",
        "\n",
        " \n",
        "TESTING_WITHMASK_DIR = experiements/dest_folder/test/without_mask/\"\n",
        "\n",
        "WITHOUTMASK_SOURCE_DIR = \"experiements/dest_folder/val/without_mask/\"\n",
        "\n",
        "TRAINING_WITHOUTMASK_DIR = \"experiements/dest_folder/train/without_mask/\"\n",
        "\n",
        "TESTING_WITHOUTMASK_DIR = \"experiements/dest_folder/test/without_mask/\"\n",
        "\n",
        "split_size = .8\n",
        "\n",
        "split_data(WITHMASK_SOURCE_DIR, TRAINING_WITHMASK_DIR, \n",
        "\n",
        "TESTING_WITHMASK_DIR, split_size)\n",
        "\n",
        "split_data(WITHOUTMASK_SOURCE_DIR, TRAINING_WITHOUTMASK_DIR, \n",
        "\n",
        "TESTING_WITHOUTMASK_DIR, split_size)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading images...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-02e2e26b354c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# the list of data (i.e., images) and class images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] loading images...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mimagePaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"/content/drive/My Drive/dataset/train_validate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imutils/paths.py\u001b[0m in \u001b[0;36mlist_files\u001b[0;34m(basePath, validExts, contains)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlist_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidExts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# loop over the directory structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrootDir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirNames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbasePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# loop over the filenames in the current directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/os.py\u001b[0m in \u001b[0;36mwalk\u001b[0;34m(top, topdown, onerror, followlinks)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \"\"\"\n\u001b[0;32m--> 335\u001b[0;31m     \u001b[0mtop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m     \u001b[0mdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0mnondirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erUKJDV7bAwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "\n",
        "    tf.keras.layers.Conv2D(100, (3,3), activation='relu', \n",
        "\n",
        "    input_shape=(150, 150, 3)),\n",
        "\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(100, (3,3), activation='relu'),\n",
        "\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "\n",
        "    tf.keras.layers.Dense(50, activation='relu'),\n",
        "\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": 18,
      "outputs": []
    }
  ]
}